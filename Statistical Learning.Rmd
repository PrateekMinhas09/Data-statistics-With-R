---
title: "Statistical Learning"
author: "ISLR- Done by Prateek Minhas"
date: "2025-10-18"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
 

```

# Ch-2: Statistical Learning

## Lab

### Basic commands

```{r}
x=c(1,3,4,5)
x
y=c(4,5,80,-3)
y
length(x)
length(x)+length(y)
x-y
z=x+y

```

#### ls() and Rm()

```{r}
ls()
rm(z)
ls()
rm(list=ls()) #empty out the list
ls()
```

#### matrix() fucntion

```{r}

x = matrix(data=c(1,2,3,4,5,6), nrow=2 , ncol = 3, byrow=TRUE)
x
y = matrix(data=c(1,2,3,4,5,6), nrow=2 , ncol = 3, byrow=FALSE)
y
```

removing the data=, nrow=, ncol= we can also write directly , by default we get byrows = false meaning the columns get filled first

```{r}
z= matrix(c(1,2,3,4,5,6), 3,2)
z
sqrt(x)
y^2
```

**rnorm()** gives random values every time we use it

```{r}
x=rnorm(50)

y=x+rnorm(50,mean=50, sd=.1)
cor(x,y)
```

we use set seed() so that we get same random numbers every time for a particular seed value

```{r}
set.seed(1303)
rnorm(50)
```

```{r}
set.seed(3)
y=rnorm(100)
mean(y)
var(y)
sqrt(var(y))
sd(y)
#as we see variance = standard deviation.sq
```

### Graphics

**plot()**

```{r}
x=rnorm(100)
y=rnorm(100)
plot(x,y, col="green")
plot(x,y,xlab = "this is x axis", ylab = "this is Y axis", main="Plot ox X vs Y")
```

**Seq()**

```{r}
x=seq(1,10)
x
y=1:10
y
z=seq(-pi,pi,length=50)
z
```

**contour() for 3d graphs**

```{r}
y=x
f= outer(x,y, function(x,y) cos(y)/(1+x^2))
contour(x,y,f)
contour(x,y,f , nlevels = 45 , add = T)
fa=(f-t(f))/2
contour(x,y,fa,nlevels = 15)
```

```{r}
image(x,y,fa)
persp(x,y,fa)
persp(x,y,fa, theta = 90, phi=30)
persp(x,y,fa, theta = 60, phi=20)
persp(x,y,fa, theta = 40, phi=15)
```

### Indexing data

```{r}
A= matrix(1:16, 4,4)
A
A[2,3]
```

```{r}
A[c(1,3),c(2,4)]
```

```{r}
A[1:3,2:4]
```

```{r}
A[1:2,]
```

```{r}
A[,1:2]
```

```{r}
A[1,]
```

-ve sign indicates that select all the elements Except those mentioned , it is like a negation

```{r}
A
A[c(1,3),]
A[-c(1,3),]#second and last row 
```

```{r}
A[-c(1,3),-c(1,3,4)]
```

```{r}
dim(A)
```

### Loading Data

```{r}
Auto = read.table("Auto.data")
#View(Auto)
head(Auto)
```

```{r}
Auto = read.table("Auto.data", na.strings = "?", header = T , stringsAsFactors = T )
head(Auto)
```

```{r}
Auto = read.csv("Auto.csv", na.strings = "?", stringsAsFactors = T)
attach(Auto)
head(Auto)
```

the strings as factors argument tells that if the value is string , treat the variable as qualitative

```{r}
dim(Auto)
```

```{r}
Auto[1:4,]
```

```{r}
Auto= na.omit(Auto)
dim(Auto) #as we see number of rows are reduced
```

```{r}
names(Auto)
```

#### Additional graphical and numerical Summaries

```{r}

plot(cylinders,mpg)
#the cylinders is quantitative
```

The **as.factor() function converts quantitative variables into qualitative** variables.

```{r}
cylinders= as.factor(cylinders)
```

***If the variable plotted on the x-axis is qualitative, then boxplots will automatically be produced by the plot() function.***

```{r}
plot(cylinders, mpg , xlab="cylinderas(qual)", ylab="mpg", col="red", varwidth=T, horizontal=F)
```

```{r}
hist(mpg)
hist(mpg, col=2)
hist(mpg,col=0, breaks=15)
```

The **pairs()** function creates a scatterplotmatrix, i.e. a scatterplot for every pair of variables.

```{r}
pairs(Auto)
pairs(~mpg + displacement + cylinders + acceleration, data=Auto)
```

```{r}
#windows()
plot(horsepower,mpg, col=12)
#identify(horsepower, mpg , name)

```

Use windows() to run the identify interactive function

```{r}
summary(Auto)
```

```{r}
summary(displacement)
```

## APPLIED EXERCISE

8.  This exercise relates to the College data set, which can be found in the file College.csv on the book website. It contains a number of variables for 777 different universities and colleges in the US

<!-- -->

(a) Use the read.csv() function to read the data into R. Call the loaded data college. Make sure that you have the directory set to the correct location for the data.

```{r}
college = read.csv("College.csv" ,stringsAsFactors = T )
attach(college)
View(college)
dim(college)
```

(b) Look at the data using the View() function. You should notice that the first column is just the name of each university. We donâ€™t really want R to treat this as data.

```{r}
rownames(college)= college[,1]
college = college[,-1]
```

(c) 

    i.  Use the summary() function to produce a numerical summary of the variables in the data set.

```{r}
summary(college)
```

```{r}
names(college)
```

ii\. Use the pairs() function to produce a scatterplot matrix of the first ten columns or variables of the data. Recall that you can reference the first ten columns of a matrix A using A[,1:10].

```{r}
pairs(college[,1:10], col=12)
```

iii. Use the plot() function to produce side-by-side boxplots of Outstate versus Private.

```{r}
plot(Private, Outstate)

```

*Here we can see that in average Private Institutes have more out of state tuition*

**iv.** Create a new qualitative variable, called Elite, by binning the Top10perc variable. We are going to divide universities into two groups based on whether or not the proportion of students coming from the top 10% of their high school classes exceeds 50%.

```{r}
if (!("Elite" %in% colnames(college))) {
  Elite = rep("No", nrow(college))
Elite[Top10perc>50]= "Yes"
Elite=as.factor(Elite)
college=data.frame(college,Elite)
}

head(college)
```

Use the summary() function to see how many elite universities there are. Now use the plot() function to produce side-by-side boxplots of Outstate versus Elite.

```{r}
summary(Elite)
```

```{r}
plot(Elite,Outstate, col=12)
```

*So in average elite people have more out of state tuition*

**v.** Use the hist() function to produce some histograms with differing numbers of bins for a few of the quantitative variables. You may find the command par(mfrow = c(2, 2)) useful: it will divide the print window into four regions so that four plots can be made simultaneously. Modifying the arguments to this function will divide the screen in other ways.

```{r}
par(mfrow=c(2,2))
hist(Top10perc)
hist(Top10perc, breaks = 15)
hist(Outstate)
hist(Outstate, breaks=15)
```

**vi. Continue exploring the data, and provide a brief summary of what you discover.**

**9.** This exercise involves the Auto data set studied in the lab. Make sure that the missing values have been removed from the data. **(a)** Which of the predictors are quantitative, and which are qualitative?

```{r}
head(Auto)
Auto= na.omit(Auto)

```

*Quantitative- mpg, cylinders, displacement, horsepower, weight, acceleration,*

*Qualitative - Year, Origin, name*

(b) What is the range of each quantitative predictor? You can answer this using the range() function.

```{r}
cylinders= as.numeric(as.character(cylinders))
range(mpg)
range(cylinders)
range(displacement)
range(horsepower, na.rm=T)
range(weight)
range(acceleration)
```

(c) What is the mean and standard deviation of each quantitative predictor?

```{r}
cat("MPG Mean:", mean(mpg), "\n")
cat("MPG SD:", sd(mpg), "\n")
cat("displacement Mean:", mean(displacement), "\n")
cat("displacement SD:", sd(displacement), "\n")
cat("weight Mean:", mean(weight), "\n")
cat("weight SD:", sd(weight), "\n")
cat("horsepower Mean:", mean(horsepower), "\n")
cat("horsepower SD:", sd(horsepower), "\n")
cat("acceleration Mean:", mean(acceleration), "\n")
cat("acceleration SD:", sd(acceleration), "\n")
```

(d) Now remove the 10th through 85th observations. What is the mean, and standard deviation of each predictor in the subset of the data that remains?

```{r}
Autosubset = Auto[-c(10:84),]
```

```{r}
with(Autosubset,{
cat("MPG Mean:", mean(mpg), "\n")
cat("MPG SD:", sd(mpg), "\n")
cat("displacement Mean:", mean(displacement), "\n")
cat("displacement SD:", sd(displacement), "\n")
cat("weight Mean:", mean(weight), "\n")
cat("weight SD:", sd(weight), "\n")
cat("horsepower Mean:", mean(horsepower), "\n")
cat("horsepower SD:", sd(horsepower), "\n")
cat("acceleration Mean:", mean(acceleration), "\n")
cat("acceleration SD:", sd(acceleration), "\n")})
```

**e),f)** are similar - Suppose that we wish to predict gas mileage (mpg) on the basis of the other variables. Do your plots suggest that any of the other variables might be useful in predicting mpg? Justify your answer.

```{r}
colnames(Auto)
```

```{r}
plot(~mpg + displacement + horsepower + weight + acceleration)
```

*we can see mpg is linearly corelated with displacement , horsepower and weight ; so these can be used as predictors for mpg , checking for corelation values*

```{r}
Auto$horsepower[Auto$horsepower == "?"] <- NA
Auto$horsepower <- as.numeric(Auto$horsepower)
Auto <- na.omit(Auto)
with(Auto, {
  cat("mpg vs displacement:", cor(mpg, displacement), "\n")
  cat("mpg vs horsepower:",  cor(mpg, horsepower), "\n")
  cat("mpg vs weight:",      cor(mpg, weight), "\n")
  cat("mpg vs acceleration:", cor(mpg, acceleration), "\n")
})
```

*as we can see apart from acceleration , rest all have high correlation values*

```{r}
with(Auto,{
  cylinders= as.factor(cylinders)
  year= as.factor(year)
  origin= as.factor(origin)
  plot(cylinders,mpg, xlab = "cylinders", ylab = "mpg")
  plot(origin,mpg, xlab="origin", ylab="mpg")
  plot(year,mpg, xlab="year", ylab="mpg")})

```

*From the first plot we can see that 4 cylinders usually achieve a higher general mpg and it decreases as the number of cylinders increase, we can say that having 4 cylinders might be most efficient*

*Second plot tells us (1- american, 2-European, 3- Japanese) that highest level of mpg is achieved by Japanese origin cars and least by american , although German cars are moderately efficient , they do have some outliers that are achieve High mpg and are highly efficient*

*Lastly, the third plot of year vs mpg showcases that cars manufactured later in the 80s are more efficient and have high mpg than earlier manufactured cars.*

**10.** This exercise involves the Boston housing data set. **(a)** To begin, load in the Boston data set. The Boston data set is part of the ISLR2 library.

```{r}
if (!requireNamespace("ISLR2", quietly = TRUE)) {
  install.packages("ISLR2")
 
}
library(ISLR2)
```

How many rows are in this data set? How many columns? What do the rows and columns represent?

```{r}
dim(Boston)
colnames(Boston)
```

*506 rows and 13 columns*

`crim`

:   per capita crime rate by town.

`zn`

:   proportion of residential land zoned for lots over 25,000 sq.ft.

`indus`

:   proportion of non-retail business acres per town.

`chas`

:   Charles River dummy variable (= 1 if tract bounds river; 0 otherwise).

`nox`

:   nitrogen oxides concentration (parts per 10 million).

`rm`

:   average number of rooms per dwelling.

`age`

:   proportion of owner-occupied units built prior to 1940.

`dis`

:   weighted mean of distances to five Boston employment centres.

`rad`

:   index of accessibility to radial highways.

`tax`

:   full-value property-tax rate per \$10,000.

`ptratio`

:   pupil-teacher ratio by town.

`lstat`

:   lower status of the population (percent).

`medv`

:   median value of owner-occupied homes in \$1000s.

**(b)** Make some pairwise scatterplots of the predictors (columns) in this data set. Describe your findings.

```{r}
pairs(Boston[, c("crim","rm","lstat","medv")])
Boston$chas = as.factor(Boston$chas)

plot(Boston$chas, Boston$lstat)
```

**(c)** Are any of the predictors associated with per capita crime rate? If so, explain the relationship.

```{r}
# Select only numeric columns
numeric_data <- Boston[, sapply(Boston, is.numeric)]

cor_matrix <- cor(numeric_data)


cor_matrix>0.7
```

*as we see from the first row , crim does not have a single strong correlation with any other predictor*

**(d)** Do any of the census tracts of Boston appear to have particularly high crime rates? Tax rates? Pupil teacher ratios? Comment on the range of each predictor.

```{r}
with(Boston, {
  print(range(crim))
  print(range(tax))
  print(range(ptratio))})

```

***Crime rate (`crim`)**: ranges from **0.006 to 88.98** â€” very wide!\
â†’ Some tracts have **extremely high crime**, while others have almost none.\
â†’ Indicates large inequality across neighborhoods.*

***Tax rate (`tax`)**: ranges from **187 to 711** â€” wide variation.\
â†’ Some areas pay nearly 4Ã— higher taxes than others.*

***Pupilâ€“teacher ratio (`ptratio`)**: ranges from **12.6 to 22.0**.\
â†’ Less variation, but still meaningful â€” suggests differences in school quality between tracts.*

**(e)** How many of the census tracts in this data set bound the Charles river?

```{r}
table(Boston$chas)
```

*35 houses are bound with Charles river*

**(f)** What is the median pupil-teacher ratio among the towns in this data set?

```{r}
median(Boston$ptratio)
```

*middle value is 19.05, half are lower and half are higher.*

**(g)** Which census tract of Boston has lowest median value of owner occupied homes? What are the values of the other predictors for that census tract, and how do those values compare to the overall ranges for those predictors? Comment on your findings.

```{r}
Boston[which.min(Boston$medv), ]

```

*With a median value of 5000 usd, the crime rate seems pretty higher than the usual average of 3, the house is not river bound and has 18.1 acres of non- rental business land. The nitrogen levels are higher than average as well, it has an average of 5 bedrooms per dwelling.*

**(h)** In this data set, how many of the census tracts average more than seven rooms per dwelling? More than eight rooms per dwelling? Comment on the census tracts that average more than eight rooms per dwelling.

```{r}
print(sum(Boston$rm>7))
print(sum(Boston$rm>8))
```

64 census tracts are \> 7

13 are grater than 8

```{r}
if (!require(MASS)) install.packages("MASS", repos = "https://cloud.r-project.org/")
if (!require(psych)) install.packages("psych", repos = "https://cloud.r-project.org/")

library(MASS)    # Boston dataset
library(psych)   # describe() function

# --- Create subsets ---
Bost7 <- Boston[Boston$rm > 7, ]
Bost8 <- Boston[Boston$rm > 8, ]

# --- Neat descriptive summaries ---
describe(Bost7)
describe(Bost8)
```
